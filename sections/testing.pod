=head1 Testowanie

Z<testing>

X<testing>

I<Testowanie> jest procesem pisania i uruchamiania krótkich kawałków kodu aby
zweryfikować że Twoje oprogramowanie zachowuje się jak założyłeś. Sprawne
testowanie automatyzuje proces który wykonywałeś już niezliczoną ilość razy:
napisz trochę kodu, uruchom go i sprawdź czy działa. Ta I<automatyzacja> jest
niezbędna. Zamiast polegać na ludziach wykonujących powtarzające się testy,
niech to robi komputer.

Perl 5 dostarcza świetne narzędzia które pomogą Ci w napisaniu odpowiednich
testów.

=head2 Test::More

X<C<Test::More>>
X<C<ok()>>
X<testing; C<ok()>>

Testowanie Perla zaczyna się od standardowego modułu C<Test::More> i jego
funkcji C<ok()>. C<ok()> przyjmuje dwa parametry, wartośc logiczną oraz tekst
który opisze cel testu:

=begin programlisting

    ok(   1, 'numer jeden powininen oznaczać prawdę'    );
    ok(   0, '... ale zero już nie'                     );
    ok(  '', 'pusty napis oznacza fałsz'                );
    ok( '!', '... ale niepusty już nie'                 );

    done_testing();

=end programlisting

X<testing; assertion>

Każdy warunek jaki możesz testować w swoim programie może w końcu przyjąć
wartość binarną. Każde I<zapewnienie> testu jest prostym pytaniem z
odpowiedzią tak lub nie: czy ten mały kawałek kodu działa jak założyłem?
Rozbudowany program może mieć tysiące osobnych warunków, ale w zasadzie im
mniejsza szczegółowośc tym lepiej. Wyizolowanie specyficznego zachowania w
osobne zapewnienia pozwoli Ci zlokalizować błędy i nieporozumienia,
szczególnie gdy będziesz modyfikował swój kod w przyszłości.

Funkcja C<done_testing()> oznajmia C<Test::More> że program z powodzeniem
wykonał wszystkie założone testy. Jeśli program napotkał wyjątek
uruchomieniowy lub z innego powodu niespodziewanie zakończył działanie przed
wywołaniem C<done_testing()>, system testujący powiadomi Cię że coś poszło
źle. Bez mechanizmu takiego jak C<done_testing()>, skąd miałbyś to
I<wiedzieć>? Wprawdzie powyższy przykładowy kod jest zbyt prosty aby zawieść,
ale zwykle kod zbyt prosty aby nawalić, zawiesza się częściej niż ktokolwiek
się spodziewa.

=begin sidebar

X<testing; plan>
X<C<plan()>>

C<Test::More> umożliwa równiez użycie I<planu testu> aby określić liczbę
poszczególnych testów które zamierzasz wykonać:

=begin programlisting

    use Test::More tests => 4;

    ok(   1, 'numer jeden powininen oznaczać prawdę'    );
    ok(   0, '... ale zero już nie'                     );
    ok(  '', 'pusty napis oznacza fałsz'                );
    ok( '!', '... ale niepusty już nie'                 );

=end programlisting

Parametr C<tests> oznajmia C<Test::More> ile testów planujesz dla danego
programu. To siatka bezpieczeństwa. Jeśli mniej niż cztery testy zostały
wykonane, coś poszło źle. Jeśli więcej niż cztery testy zostały wykonane,
również coś poszło źle.

=end sidebar

=head2 Uruchamianie testów

Z<running_tests>

Napisany kod jest teraz pełnoprawnym programem Perl 5 którego wynik jest
taki:

=begin screen

    ok 1 - numer jeden powininen oznaczać prawdę
    not ok 2 - ... ale zero już nie
    #   Failed test '... ale zero już nie'
    #   at truth_values.t line 4.
    not ok 3 - pusty napis oznacza fałsz
    #   Failed test 'pusty napis oznacza fałsz'
    #   at truth_values.t line 5.
    ok 4 - ... ale niepusty już nie
    1..4
    # Looks like you failed 2 tests of 4.

=end screen

X<TAP (Test Anything Protocol)>
X<testing; TAP>

Ten format przestrzega standardu wyniku testu nazwanego I<TAP>, I<Protokół
Testowania Wszystkiego - Test Anything Protocol> (U<http://testanything.org/>).
Oblany test TAP wyświetla informacje diagnostyczne jako pomoc przy usuwaniu
błędów z programu.

X<C<Test::Harness>>
X<C<prove>>
X<testing; C<prove>>
X<testing; running tests>

Wynik pliku testowego zawierającego wiele założeń (a w szczególności gdy wiele
z nich jest I<nieudanych>) może być zbyt szczegółowych. W więkoszści
przypadków chcesz wiedzieć czy wszystkie testy przebiegły pomyślnie lub
informacje dotyczące ewentualnych błędów. Standardowy moduł C<Test::Harness>
interpretuje TAP a jego pochodny program C<prove> uruchamia testy i wyświetla
jedynie najważniejsze informacje:

=begin screen

    $ B<prove truth_values.t>
    truth_values.t .. 1/?
    #   Failed test '... ale zero już nie'
    #   at truth_values.t line 4.

    #   Failed test 'pusty napis oznacza fałsz'
    #   at truth_values.t line 5.
    # Looks like you failed 2 tests of 4.
    truth_values.t .. Dubious, test returned 2
        (wstat 512, 0x200)
    Failed 2/4 subtests

    Test Summary Report
    -------------------
    truth_values.t (Wstat: 512 Tests: 4 Failed: 2)
      Failed tests:  2-3

=end screen

Jest tu dużo informacji które już znamy: drugi i trzeci test się nie udał
ponieważ zero i pusty napis oznaczają fałsz. Jest to proste do naprawienia
poprzez odwrócenie sensu warunku używając konwersji do wartości logicznej 
(L<boolean_coercion>):

=begin programlisting

    ok(   B<!> 0, '... ale zero już nie'        );
    ok(  B<!> '', 'pusty napis oznacza fałsz'   );

=end programlisting

Z tymi dwoma zmianami, C<prove> teraz wyświetli:

=begin screen

    $ B<prove truth_values.t>
    truth_values.t .. ok
    All tests successful.

=end screen

=begin sidebar

Zobacz C<perldoc prove> dla innych pomocnych opcji, takich jak uruchamianie
testów równolegle (C<-j>), automatyczne dodawanie F<lib/> do ścieżki bibliotek
Perla (C<-l>), rekursywne uruchomienie wszystkich plików testowych
znajdujących się w F<t/> (C<-r t>) i uruchomienie wolnych testów na początku
(C<--state=slow,save>).

X<C<proveall>>
X<testing; C<proveall> alias>
Alias powłoki bash C<proveall> może się okazać użyteczny:

    alias proveall='prove -j9 --state=slow,save -lr t'

=end sidebar

=head2 Lepsze Porównania

Chociaż sednem wszystkich zautomatyzowanych testów jest warunek logiczny
"prawda czy fałsz?", redukowanie wszystkiego do tej testu logicznego byłoby
uciążliwe i oferowałoby niewiele możliwości diagnostycznych. C<Test::More>
dostarcz kilka innych przydatnych funkcji testujących.

X<C<is()>>
X<testing; C<is()>>
X<operators; C<eq>>

Funkcja C<is()> porównuje dwie wartości używając operatora C<eq>. Jeśli te
wartości są sobie równe, test przechodzi pomyślnie. W przeciwny przypadku test
jest oblany i informacja diagnostyczna jest wyświetlona:

=begin programlisting

    is(        4, 2 + 2, 'dodawanie powinna działać' );
    is( 'placek',   100, 'placki są numerami'        );

=end programlisting

Jak zapewne oczekujesz, pierwszy test przechodzi a drugi nie:

=begin screen

    t/is_tests.t .. 1/2
    #   Failed test 'placki są numerami'
    #   at t/is_tests.t line 8.
    #          got: 'placek'
    #     expected: '100'
    # Looks like you failed 1 test of 2.

=end screen

Where C<ok()> only provides the line number of the failing test, C<is()>
displays the expected and received values.

C<is()> applies implicit scalar context to its values (L<prototypes>). This
means, for example, that you can check the number of elements in an array
without explicitly evaluating the array in scalar context:

=begin programlisting

    my @cousins = qw( Rick Kristen Alex
                      Kaycee Eric Corey );
    is( @cousins, 6, 'I should have only six cousins' );

=end programlisting

... though some people prefer to write C<scalar @cousins> for the sake of
clarity.

X<C<isnt()>>
X<testing; C<isnt()>>
X<operators; C<ne>>

C<Test::More>'s corresponding C<isnt()> function compares two values using the
C<ne> operator, and passes if they are not equal. It also provides scalar
context to its operands.

X<C<cmp_ok()>>
X<testing; C<cmp_ok()>>

Both C<is()> and C<isnt()> apply I<string comparisons> with the Perl 5
operators C<eq> and C<ne>. This almost always does the right thing, but for
complex values such as objects with overloading (L<overloading>) or dual vars
(L<dualvars>), you may prefer explicit comparison testing. The C<cmp_ok()>
function allows you to specify your own comparison operator:

=begin programlisting

    cmp_ok( 100, $cur_balance, '<=',
           'I should have at least $100' );

    cmp_ok( $monkey, $ape, '==',
           'Simian numifications should agree' );

=end programlisting

X<C<isa_ok()>>
X<testing; C<isa_ok()>>

Classes and objects provide their own interesting ways to interact with tests.
Test that a class or object extends another class (L<inheritance>) with
C<isa_ok()>:

=begin programlisting

    my $chimpzilla = RobotMonkey->new();
    isa_ok( $chimpzilla, 'Robot' );
    isa_ok( $chimpzilla, 'Monkey' );

=end programlisting

C<isa_ok()> provides its own diagnostic message on failure.

C<can_ok()> verifies that a class or object can perform the requested method
(or methods):

=begin programlisting

    can_ok( $chimpzilla, 'eat_banana' );
    can_ok( $chimpzilla, 'transform', 'destroy_tokyo' );

=end programlisting

The C<is_deeply()> function compares two references to ensure that their
contents are equal:

=begin programlisting

    use Clone;

    my $numbers   = [ 4, 8, 15, 16, 23, 42 ];
    my $clonenums = Clone::clone( $numbers );

    is_deeply( $numbers, $clonenums,
         'clone() should produce identical items' );

=end programlisting

X<CPAN; C<Test::Differences>>
X<CPAN; C<Test::Deep>>

If the comparison fails, C<Test::More> will do its best to provide a reasonable
diagnostic indicating the position of the first inequality between the
structures. See the CPAN modules C<Test::Differences> and C<Test::Deep> for
more configurable tests.

C<Test::More> has several more test functions, but these are the most useful.

=head2 Organizing Tests

X<testing; F<.t> files>
X<testing; F<t/> directory>
X<C<Module::Build>>
X<C<ExtUtils::MakeMaker>>

CPAN distributions should include a F<t/> directory containing one or more test
files named with the F<.t> suffix.  By default, when you build a distribution
with C<Module::Build> or C<ExtUtils::MakeMaker>, the testing step runs all of
the F<t/*.t> files, summarizes their output, and succeeds or fails on the
results of the test suite as a whole.  There are no concrete guidelines on how
to manage the contents of individual F<.t> files, though two strategies are
popular:

=over 4

=item * Each F<.t> file should correspond to a F<.pm> file

=item * Each F<.t> file should correspond to a feature

=back

A hybrid approach is the most flexible; one test can verify that all of your
modules compile, while other tests verify that each module behaves as intended.
As distributions grow larger, the utility of managing tests in terms of
features becomes more compelling; larger test files are more difficult to
maintain.

Separate test files can also speed up development. If you're adding the ability
to breathe fire to your C<RobotMonkey>, you may want only to run the
F<t/breathe_fire.t> test file.  When you have the feature working to your
satisfaction, run the entire test suite to verify that local changes have no
unintended global effects.

=head2 Other Testing Modules

X<C<Test::Builder>>
X<testing; C<Test::Builder>>

C<Test::More> relies on a testing backend known as C<Test::Builder>.  The
latter module manages the test plan and coordinates the test output into TAP.
This design allows multiple test modules to share the same C<Test::Builder>
backend.  Consequently, the CPAN has hundreds of test modules available--and
they can all work together in the same program.

X<CPAN; C<Test::Exception>>
X<CPAN; C<Test::Fatal>>
X<CPAN; C<Test::MockObject>>
X<CPAN; C<Test::MockModule>>
X<CPAN; C<Test::WWW::Mechanize>>
X<CPAN; C<Plack::Test>>
X<CPAN; C<Test::WWW::Mechanize::PSGI>>
X<CPAN; C<Test::Database>>
X<CPAN; C<DBICx::TestDatabase>>
X<CPAN; C<DBIx::Class>>
X<CPAN; C<Test::Class>>
X<CPAN; C<Test::Routine>>
X<CPAN; C<Test::Differences>>
X<CPAN; C<Test::Deep>>
X<CPAN; C<Test::LongString>>
X<CPAN; C<Devel::Cover>>

=over 4

=item * C<Test::Fatal> helps test that your code throws (and does not throw)
exceptions appropriately. You may also encounter C<Test::Exception>.

=item * C<Test::MockObject> and C<Test::MockModule> allow you to test difficult
interfaces by I<mocking> (emulating but producing different results).

=item * C<Test::WWW::Mechanize> helps test web applications, while
C<Plack::Test>, C<Plack::Test::Agent>, and the subclass
C<Test::WWW::Mechanize::PSGI> can do so without using an external live web
server.

=item * C<Test::Database> provides functions to test the use and abuse of
databases. C<DBICx::TestDatabase> helps test schemas built with C<DBIx::Class>.

=item * C<Test::Class> offers an alternate mechanism for organizing test
suites.  It allows you to create classes in which specific methods group tests.
You can inherit from test classes just as your code classes inherit from each
other.  This is an excellent way to reduce duplication in test suites.  See
Curtis Poe's excellent C<Test::Class>
seriesN<U<http://www.modernperlbooks.com/mt/2009/03/organizing-test-suites-with-testclass.html>>.
The newer C<Test::Routine> distribution offers similar possibilities through
the use of Moose (L<moose>).

=item * C<Test::Differences> tests strings and data structures for equality and
displays any differences in its diagnostics. C<Test::LongString> adds similar
assertions.

=item * C<Test::Deep> tests the equivalence of nested data structures
(L<nested_data_structures>).

=item * C<Devel::Cover> analyzes the execution of your test suite to report on
the amount of your code your tests actually exercises.  In general, the more
coverage the better--though 100% coverage is not always possible, 95% is far
better than 80%.

=back

See the Perl QA project (U<http://qa.perl.org/>) for more information about
testing in Perl.
